---
# AWS SSH access:
- name: Ensure we have an SSH key pair for ec2
  ec2_key:
    name: "{{ libsimple_instance_name }}"
    region: "{{ aws_region }}"
  register: ec2_key

- name: Ensure private key exists in local admin's .ssh directory
  copy:
    content: "{{ ec2_key.key.private_key }}"
    dest: "~/.ssh/{{ libsimple_instance_name }}.pem"
    mode: 0600
  when: ec2_key.changed

# AWS VPC:

- name: Ensure a dedicated VPC for the AWS components
  ec2_vpc_net:
    name: "{{ libsimple_server_type }}-{{ libsimple_instance_name }}"
    cidr_block: 172.42.0.0/16
    region: "{{ aws_region }}"
  register: ec2_vpc
- set_fact:
    vpc_id: "{{ ec2_vpc.vpc.id }}"

# AWS VPC Internet Gateway:

- name: Ensure an Internet Gateway is attached to the VPC
  ec2_vpc_igw:
    vpc_id: "{{ vpc_id }}"
    region: "{{ aws_region }}"
    state: present
  register: igw

# AWS VPC Subnets:

- name: Ensure first dedicated VPC subnet for the AWS components
  ec2_vpc_subnet:
    state: present
    region: "{{ aws_region }}"
    az: "{{ aws_az_1 }}"
    vpc_id: "{{ vpc_id }}"
    cidr: 172.42.0.0/20
    resource_tags:
      Name: "{{ libsimple_server_type }}-{{ libsimple_instance_name }}-subnet1"
  register: vpc_subnet_1
- set_fact:
    vpc_subnet_1_id: "{{ vpc_subnet_1.subnet.id }}"

# Create (public) route for subnet to the Internet Gateway
- name: Attach route for first subnet to Internet Gateway
  ec2_vpc_route_table:
    vpc_id: "{{ vpc_id }}"
    region: "{{ aws_region }}"
    tags:
      Name: Public
    subnets:
      - "{{ vpc_subnet_1_id }}"
    routes:
      - dest: 0.0.0.0/0
        gateway_id: "{{ igw.gateway_id }}"
  register: public_route_table    

# Additional subnets in separate AWS regions are required for RDS Subnet group
- name: Ensure second dedicated VPC subnet for the RDS Subnet group
  ec2_vpc_subnet:
    state: present
    region: "{{ aws_region }}"
    az: "{{ aws_az_2 }}"
    vpc_id: "{{ vpc_id }}"
    cidr: 172.42.16.0/20
    resource_tags:
      Name: "{{ libsimple_server_type }}-{{ libsimple_instance_name }}-subnet2"
  register: vpc_subnet_2
- set_fact:
    vpc_subnet_2_id: "{{ vpc_subnet_2.subnet.id }}"

- name: Ensure third dedicated VPC subnet for the RDS Subnet group
  ec2_vpc_subnet:
    state: present
    region: "{{ aws_region }}"
    az: "{{ aws_az_3 }}"
    vpc_id: "{{ vpc_id }}"
    cidr: 172.42.32.0/20
    resource_tags:
      Name: "{{ libsimple_server_type }}-{{ libsimple_instance_name }}-subnet3"
  register: vpc_subnet_3
- set_fact:
    vpc_subnet_3_id: "{{ vpc_subnet_3.subnet.id }}"

- name: Ensure RDS subnet group with subnets in different AWS availability zones
  rds_subnet_group:
    region: "{{ aws_region }}"
    state: present
    name: libsimple-postgres
    description: "{{ libsimple_server_type }}-{{ libsimple_instance_name }}"
    subnets:
      - "{{ vpc_subnet_1_id }}"
      - "{{ vpc_subnet_2_id }}"
      - "{{ vpc_subnet_3_id }}"

# AWS EC2 Security Group:

- name: Ensure security group exists and open SSH port from the ansible control machine
  ec2_group:
    name: "EC2-{{ libsimple_server_type }}-{{ libsimple_instance_name }}"
    description: "Firewall rules for the {{ libsimple_server_type }}-{{ libsimple_instance_name }} EC2 instance"
    region: "{{ aws_region }}"
    vpc_id: "{{ vpc_id }}"
    # To preserve any IPs from add-admin-ips.yml upon re-running this playbook:
    purge_rules: no
    # Initial rules:
    rules:
      - proto: tcp
        from_port: 22
        to_port: 22
        cidr_ip: "{{ admin_ip }}/32"
      - proto: tcp
        from_port: 80
        to_port: 80
        cidr_ip: "0.0.0.0/0"
  register: ec2_sg

# CHECK/USE AVAILABLE EC2 IMAGE
# Search for the AMI specified in the AWS role
- name: Determine whether specified ec2_image ID is available
  ec2_ami_find:
    owner: aws-marketplace
    region: "{{ aws_region }}"
    ami_id: "{{ ec2_image }}"
  register: ami_find1

# Search for the latest specified AMI
- name: If original image is not available, search for latest image
  ec2_ami_find:
    region: "{{ aws_region }}"
    name: "{{ ec2_image_type }}*"
    sort: creationDate
    sort_order: descending
    sort_end: 1
  register: ami_find2
  when: ami_find1.results|length == 0

# Set proper AMI image ID
- name: Set proper AMI image ID
  set_fact:
    os_image_id: "{{ ami_find1.results.0.ami_id  }}"
  when: ami_find1.results|length > 0

- set_fact:
    os_image_id: "{{ ami_find2.results.0.ami_id }}"
  when: (ami_find2.results is defined and ami_find2.results|length > 0)

- debug:
    msg: "Using {{ ec2_image_type }} image id: {{ os_image_id }}"

# Create AWS EC2 instance:

- name: Ensure EC2 instance exists with tag "{{ libsimple_server_type }}-{{ libsimple_instance_name }}"
  local_action:
    module: ec2
    wait: yes
    wait_timeout: 1200
    region: "{{ aws_region }}"
    zone: "{{ aws_az_1 }}"
    instance_type: "{{ ec2_instance_type }}"
    exact_count: 1
    count_tag:
      Name: "{{ libsimple_server_type }}-{{ libsimple_instance_name }}"
    instance_tags: '{"Name":"{{ libsimple_server_type }}-{{ libsimple_instance_name }}","Type":"{{ libsimple_server_type }}","Environment":"{{ libsimple_environment }}"}'
    key_name: "{{ libsimple_instance_name }}"
    group_id: "{{ ec2_sg.group_id }}"
    image: "{{ os_image_id }}"
    vpc_subnet_id: "{{ vpc_subnet_1_id }}"
    assign_public_ip: yes
# The root device name may be different for each AMI used; CentOS7 differs from examples
    volumes:
    - device_name: "/dev/{{ ec2_root_device_name }}"
      device_type: "{{ ec2_root_device_type }}"
      volume_size: "{{ ec2_volume_size }}"
      delete_on_termination: true
# TODO: May need to create swap volume as well
  register: ec2

- name: Add instance to host group in working memory
  add_host: hostname="{{ item.public_ip }}" groupname="{{ libsimple_server_type }}-servers" ansible_ssh_private_key_file="~/.ssh/{{ libsimple_instance_name }}.pem"
  with_items:
    - "{{ ec2.instances }}"
    - "{{ ec2.tagged_instances }}"

- name: Check SSH to make sure the instance boots
  wait_for: host={{ item.public_ip }} port=22 delay=60 timeout=720 state=started
  with_items: "{{ ec2.instances }}"

- name: Store insance IPs for use in later plays
  set_fact:
    ec2_ip: "{{ item.public_ip }}"
    ec2_private_ip: "{{ item.private_ip }}"
  with_items:
    - "{{ ec2.instances }}"
    - "{{ ec2.tagged_instances }}"

# AWS RDS Security Group:

- name: Ensure security group exists for RDS insance with PostgreSQL port open to the private IP of the EC2 instance
  ec2_group:
    name: "RDS-{{ libsimple_server_type }}-{{ libsimple_instance_name }}"
    description: "Firewall rules for the {{ libsimple_server_type }}-{{ libsimple_instance_name }} RDS instance"
    region: "{{ aws_region }}"
    vpc_id: "{{ vpc_id }}"
    rules:
      - proto: tcp
        from_port: 5432
        to_port: 5432
        cidr_ip: "{{ ec2_private_ip }}/32"
  register: rds_sg
- debug: var=rds_sg.group_id

# AWS RDS Parameter Group
# (deviates from default to enable fuller logging for review during testing)

- name: Ensure PostgreSQL logging is set appropriately for full review of actions
  rds_param_group:
    name: "{{ rds_logging_parameter_group }}"
    description: 'Specific parameters to enable broader logging'
    region: "{{ aws_region }}"
    state: present
    engine: "{{ rds_engine_type }}{{ rds_engine_version }}"
    params:
      log_statement: "all"          # options include: none (errors), all, ddl, or mod
      log_min_duration_statement: 0 # zero indicates include all durations (not slow log)
      log_duration: 1               # add duration to all queries
      log_timezone: "{{ rds_log_timezone }}"
    immediate: yes
#   tags:
#      Environment: testing
#      Application: ''

# Add a wait period for parameter group to be added (docs say up to 5 minutes)
- name: Wait five minutes for parameter group to be available
  wait_for: timeout=300
  delegate_to: localhost

# AWS RDS Database:

- name: Ensure PostgreSQL database exists in AWS RDS
  rds:
    command: create
    wait: yes
    wait_timeout: 1200
    instance_name: "{{ libsimple_server_type }}-{{ libsimple_instance_name.replace(' ','-') }}"
    tags:
      Environment: "{{ libsimple_environment }}"
      Application: "{{ libsimple_server_type }}"
    region: "{{ aws_region }}"
    zone: "{{ rds_instance_primary_zone }}"
    instance_type: "{{ rds_instance_type }}"
    db_engine: "{{ rds_engine_type }}"
    engine_version: "{{ rds_engine_version }}"
    size: "{{ rds_size }}"
#    iops: "{{ rds_iops }}" # only when storage type io1 is used; not currently supported
    subnet: libsimple-postgres
    vpc_security_groups: "{{ rds_sg.group_id }}"
    multi_zone: no
    port: 5432
    # Create a database on the instance
    db_name: "{{ psql_db_name }}"
    username: "{{ psql_username }}"
    password: "{{ psql_password }}"
    parameter_group: "{{ rds_logging_parameter_group }}"
    backup_window: "{{ rds_backup_window }}"
    backup_retention: 1     # one-day default; fine for testing
    maint_window: "{{ rds_maint_window }}"
  register: rds

- set_fact:
    psql_endpoint: "{{ rds.instance.endpoint }}"

- name: Display PostgresSQL endpoint
  debug:
    var: psql_endpoint

- set_fact:
    ec2_es_domain_name: "{{ libsimple_server_type|lower }}-{{ libsimple_instance_name.replace(' ','-')|lower }}"

- name: Create ElasticSearch cluster
  ec2_elasticsearch:
    name: "{{ ec2_es_domain_name[0:28] }}"
    elasticsearch_version: "1.5"
    region: "{{ aws_region }}"
    instance_type: "t2.small.elasticsearch"
    instance_count: 1
    dedicated_master: False
    zone_awareness: False
# dedicated_master_instance_type: "t2.micro.elasticsearch"
# dedicated_master_instance_count: 2
    ebs: True
    volume_type: "standard"
    volume_size: 10
    snapshot_hour: 13
    access_policies: "{{ lookup('template', 'templates/es_cluster_policies.j2', convert_data=False) | from_json }}"
# profile: "myawsaccount"
  register: aws_es_service
- debug: var=aws_es_service


